{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Algorithms used\\nnaivebayes>>>MultinomialNB ,BernoulliNB\\nlinear_model>>>>>Logistic regression ,SGDClassifier, \\nSVM>>>>SVC ,LinearSVC ,NuSVC\\nRandomForest\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''importing required lib'''\n",
    "import numpy as np # to deal with numbers and array\n",
    "import pandas as pd #for handling dataframes\n",
    "from sklearn.utils import shuffle #use to shuffle dataframe\n",
    "\n",
    "''' lib required for creating a model  i.e text data into array of matrix'''\n",
    "from sklearn.feature_extraction.text import CountVectorizer  ## BOW Model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  ## TFIDF Model\n",
    "# for converting text data into array \n",
    "\n",
    "''' lib required for cleaning of data'''\n",
    "from nltk.corpus import stopwords #containing stopwords\n",
    "from nltk.stem.porter import PorterStemmer # use to fing a core meaning of words \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re #used for regular expression operation\n",
    "import os\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "'''Algorithms used\n",
    "naivebayes>>>MultinomialNB ,BernoulliNB\n",
    "linear_model>>>>>Logistic regression ,SGDClassifier, \n",
    "SVM>>>>SVC ,LinearSVC ,NuSVC\n",
    "RandomForest\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.read_csv('crisis3.csv',encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>other_useful_information</td>\n",
       "      <td>'592326564110585856'</td>\n",
       "      <td>RT @divyaconnects: Reached #Kathmandu finally!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>missing_trapped_or_found_people</td>\n",
       "      <td>'592616512642420737'</td>\n",
       "      <td>fears for Foreigners missing in Nepal earthqua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>injured_or_dead_people</td>\n",
       "      <td>'592686635520827393'</td>\n",
       "      <td>RT @ParisBurned: 3,700 people dead is absolute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>donation_needs_or_offers_or_volunteering_services</td>\n",
       "      <td>'593301431366635520'</td>\n",
       "      <td>Earthquake in Nepal - Please help Kapil #crowd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>other_useful_information</td>\n",
       "      <td>'592590231519555584'</td>\n",
       "      <td>Nepals Slowing Economy Set for Freefall Witho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              label  \\\n",
       "0           0                           other_useful_information   \n",
       "1           1                    missing_trapped_or_found_people   \n",
       "2           2                             injured_or_dead_people   \n",
       "3           3  donation_needs_or_offers_or_volunteering_services   \n",
       "4           4                           other_useful_information   \n",
       "\n",
       "               tweet_id                                         tweet_text  \n",
       "0  '592326564110585856'  RT @divyaconnects: Reached #Kathmandu finally!...  \n",
       "1  '592616512642420737'  fears for Foreigners missing in Nepal earthqua...  \n",
       "2  '592686635520827393'  RT @ParisBurned: 3,700 people dead is absolute...  \n",
       "3  '593301431366635520'  Earthquake in Nepal - Please help Kapil #crowd...  \n",
       "4  '592590231519555584'  Nepals Slowing Economy Set for Freefall Witho...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head() #showing first five values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataframe['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20624, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape # describing the size of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'tweet_id', 'tweet_text'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.columns #information about the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>20624</td>\n",
       "      <td>20624</td>\n",
       "      <td>20624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>15</td>\n",
       "      <td>18743</td>\n",
       "      <td>18743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>other_useful_information</td>\n",
       "      <td>'383770753369264129'</td>\n",
       "      <td>RT @AnasMallick: Day3 &amp;amp; CM Balochistan sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>6231</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           label              tweet_id  \\\n",
       "count                      20624                 20624   \n",
       "unique                        15                 18743   \n",
       "top     other_useful_information  '383770753369264129'   \n",
       "freq                        6231                     2   \n",
       "\n",
       "                                               tweet_text  \n",
       "count                                               20624  \n",
       "unique                                              18743  \n",
       "top     RT @AnasMallick: Day3 &amp; CM Balochistan sti...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe() # describe the dataframe internal information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label         0\n",
       "tweet_id      0\n",
       "tweet_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.isnull().sum() #determining whether there is a empty value is present or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['other_useful_information', 'missing_trapped_or_found_people',\n",
       "       'injured_or_dead_people',\n",
       "       'donation_needs_or_offers_or_volunteering_services',\n",
       "       'sympathy_and_emotional_support', 'not_related_or_irrelevant',\n",
       "       'caution_and_advice', 'displaced_people_and_evacuations',\n",
       "       'infrastructure_and_utilities_damage', 'prevention',\n",
       "       'disease_transmission', 'deaths_reports',\n",
       "       'disease_signs_or_symptoms', 'affected_people', 'treatment'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other_userful_information=dataframe[dataframe['label']==\"other_useful_information\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_class(x):\n",
    "    if x == \"deaths_reports\" or x==\"injured_or_dead_people\" or x==\"affected_people\":\n",
    "        return \"affectedPeople_or_injured_or_dead_people_or_DeathReports\"\n",
    "    elif x==\"disease_transmission\" or x==\"disease_signs_or_symptoms\":\n",
    "        return \"disease_transmission_or_disease_signs_or_symptoms\"\n",
    "    elif x==\"displaced_people_and_evacuations\" or x==\"missing_trapped_or_found_people\":\n",
    "        return 'missing_trapped_or_found_people'\n",
    "    elif x==\"caution_and_advice\" or x==\"prevention\":\n",
    "        return \"prevention_or_caution_and_advice\"\n",
    "    else:\n",
    "        return x\n",
    "        \n",
    "dataframe[\"label\"]=dataframe[\"label\"].map(same_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_useful_information                                    6231\n",
      "affectedPeople_or_injured_or_dead_people_or_DeathReports    3051\n",
      "not_related_or_irrelevant                                   2758\n",
      "donation_needs_or_offers_or_volunteering_services           2288\n",
      "sympathy_and_emotional_support                              1875\n",
      "infrastructure_and_utilities_damage                         1336\n",
      "prevention_or_caution_and_advice                            1282\n",
      "missing_trapped_or_found_people                              751\n",
      "disease_transmission_or_disease_signs_or_symptoms            682\n",
      "treatment                                                    370\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataframe['label'].value_counts()) # number of events with there count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe=dataframe.drop(dataframe[(dataframe['label']==\"other_useful_information\")].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe[dataframe['label']==\"not_related_or_irrelevant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe.to_csv('crisis3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1={'other_useful_information':0, 'missing_trapped_or_found_people':1,\n",
    "       'affectedPeople_or_injured_or_dead_people_or_DeathReports':2,\n",
    "       'donation_needs_or_offers_or_volunteering_services':3,\n",
    "       'sympathy_and_emotional_support':4, 'not_related_or_irrelevant':5,\n",
    "       'prevention_or_caution_and_advice':6,\n",
    "       'infrastructure_and_utilities_damage':7,\n",
    "       'disease_transmission_or_disease_signs_or_symptoms':8, 'treatment':9}\n",
    "def label(x):\n",
    "    return label1[x];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"numeric_label\"]=dataframe[\"label\"].map(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_useful_information                                    6231\n",
       "affectedPeople_or_injured_or_dead_people_or_DeathReports    3051\n",
       "not_related_or_irrelevant                                   2758\n",
       "donation_needs_or_offers_or_volunteering_services           2288\n",
       "sympathy_and_emotional_support                              1875\n",
       "infrastructure_and_utilities_damage                         1336\n",
       "prevention_or_caution_and_advice                            1282\n",
       "missing_trapped_or_found_people                              751\n",
       "disease_transmission_or_disease_signs_or_symptoms            682\n",
       "treatment                                                    370\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['label'].value_counts() # number of events with there count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3051\n",
       "3    2288\n",
       "4    1875\n",
       "7    1336\n",
       "6    1282\n",
       "1     751\n",
       "8     682\n",
       "9     370\n",
       "Name: numeric_label, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['numeric_label'].value_counts() # number of events with there count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @cuteinsan: In this horrible situation in nepal our God  @Gurmeetramrahim  can help pita ji they really need your simpathy #MSGHelpEarth",
      "\n",
      "event extracted>>>\n",
      "sympathy_and_emotional_support\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tweet with corresponding label'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataframe['tweet_text'][5])\n",
    "print(\"event extracted>>>\")\n",
    "print(dataframe['label'][5])\n",
    "'''tweet with corresponding label'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18743"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['tweet_id'].nunique() #number of unique tweet ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'very', 'further', \"don't\", 'she', 'doesn', 'they', 'if', 'too', 'out', 'same', 'most', \"it's\", 'itself', 'i', 'him', 'than', 's', 'mustn', 'own', 'but', 'all', 'can', 'am', 'wasn', 'myself', 'with', 'these', 'm', 't', 'who', \"couldn't\", 'by', \"mightn't\", \"wasn't\", 'before', 'where', 're', 'yourself', 'there', 'haven', 'ain', 'was', \"you'll\", 'aren', 'd', 'after', 'because', 'shan', 'each', 'himself', 'being', 'that', 'some', \"hadn't\", 'hasn', 'mightn', 'herself', \"needn't\", 'about', 'shouldn', \"won't\", 'and', 'once', 'an', \"aren't\", 'having', 'how', 'until', \"isn't\", 'in', 'ours', 'doing', 'y', 'again', 'not', 've', 'which', 'or', 'didn', 'yourselves', 'the', \"should've\", 'at', 'up', 'for', \"you've\", 'from', 'into', \"shouldn't\", \"that'll\", 'are', 'hers', 'when', 'their', 'my', 'do', 'won', \"mustn't\", 'were', 'few', 'yours', 'theirs', 'while', 'ma', 'through', 'over', 'should', 'why', \"wouldn't\", 'isn', 'ourselves', 'under', 'its', 'just', 'has', \"she's\", 'his', 'a', 'whom', 'be', \"haven't\", \"shan't\", 'them', 'those', 'll', 'weren', \"weren't\", 'during', 'against', 'below', 'been', 'will', \"doesn't\", 'did', 'to', 'does', 'as', 'above', 'down', 'our', \"you'd\", 'themselves', 'here', \"didn't\", 'between', 'hadn', 'have', 'her', 'o', 'now', \"hasn't\", 'we', 'other', 'your', 'any', 'me', 'what', 'only', 'couldn', 'don', 'on', 'it', 'both', 'more', 'wouldn', 'you', 'is', 'this', 'so', 'no', 'then', \"you're\", 'such', 'nor', 'he', 'needn', 'had', 'of', 'off'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = [\"RT\",'rt'] #creating a list of extra stop words\n",
    "stop = stop_words.union(new_words) #adding words into corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input : The whole dataframe will be send to the function\n",
    "Output : Column with clean tweets tweet will be added\n",
    "Function perform following operation:\n",
    "       1. Clean text from html tags\n",
    "       2. Clean text from punctuations and special characters\n",
    "       3. Retain only non-numeric Latin characters with lenght > 2\n",
    "       4. Remove stopwords from the sentence\n",
    "       5. Apply stemming to all the words in the sentence\n",
    "'''\n",
    "def clean_tweets(dataset):\n",
    "    corpus = []\n",
    "    for i in range(0, dataset.shape[0]):\n",
    "        text=dataset['tweet_text'][i]\n",
    "        #hte line data.shape will return [row size,columnsize ] from which we are taking row size using index 0\n",
    "        \n",
    "        #remove @mentions\n",
    "        rg=re.compile('@[^, ]*\\s*')\n",
    "        text=re.sub(rg,\" \",text)\n",
    "\n",
    "        #remove urls\n",
    "        rg=re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        text=re.sub(rg,\" \",text)\n",
    "\n",
    "        #Remove punctuations\n",
    "        text = re.sub('[^a-zA-Z0-9]', ' ',text)\n",
    "\n",
    "        #Convert to lowercase\n",
    "        text = text.lower()\n",
    "\n",
    "        #remove tags\n",
    "        text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "\n",
    "        # remove special characters and digits\n",
    "        #text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "        text=re.sub(\"(\\\\W)+\",\" \",text)\n",
    "\n",
    "        ##Convert to list from string\n",
    "        text = text.split()\n",
    "\n",
    "        ##Stemming\n",
    "        ps=PorterStemmer()    #Lemmatisation\n",
    "        lem = WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text if not word in\n",
    "                stop_words and len(word)>2]\n",
    "        text = \" \".join(text)\n",
    "        corpus.append(text)\n",
    "    dataset['preprocessed']=corpus\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>other_useful_information</td>\n",
       "      <td>'592326564110585856'</td>\n",
       "      <td>RT @divyaconnects: Reached #Kathmandu finally!...</td>\n",
       "      <td>reached kathmandu finally lot indian stranded ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>missing_trapped_or_found_people</td>\n",
       "      <td>'592616512642420737'</td>\n",
       "      <td>fears for Foreigners missing in Nepal earthqua...</td>\n",
       "      <td>fear foreigner missing nepal earthquake death ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>affectedPeople_or_injured_or_dead_people_or_De...</td>\n",
       "      <td>'592686635520827393'</td>\n",
       "      <td>RT @ParisBurned: 3,700 people dead is absolute...</td>\n",
       "      <td>700 people dead absolutely devastating country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>donation_needs_or_offers_or_volunteering_services</td>\n",
       "      <td>'593301431366635520'</td>\n",
       "      <td>Earthquake in Nepal - Please help Kapil #crowd...</td>\n",
       "      <td>earthquake nepal please help kapil crowdfundin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>other_useful_information</td>\n",
       "      <td>'592590231519555584'</td>\n",
       "      <td>Nepals Slowing Economy Set for Freefall Witho...</td>\n",
       "      <td>nepal slowing economy set freefall without wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label              tweet_id  \\\n",
       "0                           other_useful_information  '592326564110585856'   \n",
       "1                    missing_trapped_or_found_people  '592616512642420737'   \n",
       "2  affectedPeople_or_injured_or_dead_people_or_De...  '592686635520827393'   \n",
       "3  donation_needs_or_offers_or_volunteering_services  '593301431366635520'   \n",
       "4                           other_useful_information  '592590231519555584'   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  RT @divyaconnects: Reached #Kathmandu finally!...   \n",
       "1  fears for Foreigners missing in Nepal earthqua...   \n",
       "2  RT @ParisBurned: 3,700 people dead is absolute...   \n",
       "3  Earthquake in Nepal - Please help Kapil #crowd...   \n",
       "4  Nepals Slowing Economy Set for Freefall Witho...   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  reached kathmandu finally lot indian stranded ...  \n",
       "1  fear foreigner missing nepal earthquake death ...  \n",
       "2  700 people dead absolutely devastating country...  \n",
       "3  earthquake nepal please help kapil crowdfundin...  \n",
       "4  nepal slowing economy set freefall without wor...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=clean_tweets(dataframe)# function calling for preprocessed tweet\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20624, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith open('mainprocessed_dataset20624.pickle' ,'wb') as f:\\n    pickle.dump(dataframe,f)\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "with open('mainprocessed_dataset20624.pickle' ,'wb') as f:\n",
    "    pickle.dump(dataframe,f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in =open('scripts/preprocessed.pickle' ,'rb')\n",
    "dataframe=pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake in Nepal - Please help Kapil #crowdfunding fundrazr Support and Retweet http://t.co/mFEyQ85js9 via MechanismOfWar\n",
      "After preprocessing>>>>>>>>>>>>>>>>>\n",
      "earthquake nepal please help kapil crowdfunding fundrazr support retweet via mechanismofwar\n"
     ]
    }
   ],
   "source": [
    "print(dataframe['tweet_text'][2])\n",
    "print('After preprocessing>>>>>>>>>>>>>>>>>')\n",
    "print(dataframe['preprocessed'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corresponding result >>>>>>>>>>>>>>>>>>>>\n",
      "['missing_trapped_or_found_people'\n",
      " 'affectedPeople_or_injured_or_dead_people_or_DeathReports'\n",
      " 'donation_needs_or_offers_or_volunteering_services'\n",
      " 'sympathy_and_emotional_support'\n",
      " 'affectedPeople_or_injured_or_dead_people_or_DeathReports']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = dataframe['preprocessed'].values# text data will be converted into operational format\n",
    "y=dataframe['label'].values #same as it is'''\n",
    "#print(X[0:5])\n",
    "print('corresponding result >>>>>>>>>>>>>>>>>>>>')\n",
    "print(y[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11635, 11452)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vect = TfidfVectorizer()# initializing the vector by creating object\n",
    "X= tf_idf_vect.fit_transform(X) # tranforming text data into vector format\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"tfidf_model_11452.pickle\",'wb') as f:\n",
    "    pickle.dump(tf_idf_vect,f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuuracy>>>> 86.08247422680412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_svc_model = LinearSVC(multi_class=\"ovr\") # note perform changes in attribute to get bettter accuracy\n",
    "linear_svc_model.fit(X_train,y_train)#passing data into model for training\n",
    "y_pred=linear_svc_model.predict(X_test)#after training we pass rest 20%of data for testing purpose\n",
    "acc=metrics.accuracy_score(y_test,y_pred) \n",
    "#here we are passing actual result and predicted result to find out accuracy\n",
    "print('acuuracy>>>>',acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"linearSvc.pickle\" ,'wb') as f:\n",
    "    pickle.dump(linear_svc_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom xgboost import XGBClassifier\\nfrom time import ctime ,time\\nprint(ctime())\\nxgbm=XGBClassifier(objective=\"multi:softmax\",max_depth=7,n_estimator=800,learning_rate=0.7)\\nxgbm.fit(X_train,y_train)\\ny_pred=xgbm.predict(X_test)\\nacc=metrics.accuracy_score(y_test,y_pred) \\n#here we are passing actual result and predicted result to find out accuracy\\nprint(\\'acuuracy>>>>\\',acc*100)\\nprint(ctime())\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from xgboost import XGBClassifier\n",
    "from time import ctime ,time\n",
    "print(ctime())\n",
    "xgbm=XGBClassifier(objective=\"multi:softmax\",max_depth=7,n_estimator=800,learning_rate=0.7)\n",
    "xgbm.fit(X_train,y_train)\n",
    "y_pred=xgbm.predict(X_test)\n",
    "acc=metrics.accuracy_score(y_test,y_pred) \n",
    "#here we are passing actual result and predicted result to find out accuracy\n",
    "print('acuuracy>>>>',acc*100)\n",
    "print(ctime())\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
