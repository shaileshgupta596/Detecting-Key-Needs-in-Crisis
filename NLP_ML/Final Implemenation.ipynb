{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  ## TFIDF Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in=open('final_dataset.pickle','rb')\n",
    "final_dataset=pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>missing_trapped_or_found_people</td>\n",
       "      <td>'592616512642420737'</td>\n",
       "      <td>fears for Foreigners missing in Nepal earthqua...</td>\n",
       "      <td>fear foreigner missing nepal earthquake death ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>affectedPeople_or_injured_or_dead_people_or_De...</td>\n",
       "      <td>'592686635520827393'</td>\n",
       "      <td>RT @ParisBurned: 3,700 people dead is absolute...</td>\n",
       "      <td>700 people dead absolutely devastating country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>donation_needs_or_offers_or_volunteering_services</td>\n",
       "      <td>'593301431366635520'</td>\n",
       "      <td>Earthquake in Nepal - Please help Kapil #crowd...</td>\n",
       "      <td>earthquake nepal please help kapil crowdfundin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sympathy_and_emotional_support</td>\n",
       "      <td>'592637329786830848'</td>\n",
       "      <td>RT @cuteinsan: In this horrible situation in n...</td>\n",
       "      <td>horrible situation nepal god help pita really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>affectedPeople_or_injured_or_dead_people_or_De...</td>\n",
       "      <td>'592955183753203715'</td>\n",
       "      <td>VIDEO REPORT Kathmandu overwhelmed by rubble a...</td>\n",
       "      <td>video report kathmandu overwhelmed rubble eart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label              tweet_id  \\\n",
       "0                    missing_trapped_or_found_people  '592616512642420737'   \n",
       "1  affectedPeople_or_injured_or_dead_people_or_De...  '592686635520827393'   \n",
       "2  donation_needs_or_offers_or_volunteering_services  '593301431366635520'   \n",
       "3                     sympathy_and_emotional_support  '592637329786830848'   \n",
       "4  affectedPeople_or_injured_or_dead_people_or_De...  '592955183753203715'   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  fears for Foreigners missing in Nepal earthqua...   \n",
       "1  RT @ParisBurned: 3,700 people dead is absolute...   \n",
       "2  Earthquake in Nepal - Please help Kapil #crowd...   \n",
       "3  RT @cuteinsan: In this horrible situation in n...   \n",
       "4  VIDEO REPORT Kathmandu overwhelmed by rubble a...   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  fear foreigner missing nepal earthquake death ...  \n",
       "1  700 people dead absolutely devastating country...  \n",
       "2  earthquake nepal please help kapil crowdfundin...  \n",
       "3  horrible situation nepal god help pita really ...  \n",
       "4  video report kathmandu overwhelmed rubble eart...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20624, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prevention_or_caution_and_advice                            3998\n",
       "affectedPeople_or_injured_or_dead_people_or_DeathReports    3749\n",
       "donation_needs_or_offers_or_volunteering_services           3059\n",
       "not_related_or_irrelevant                                   2758\n",
       "sympathy_and_emotional_support                              2369\n",
       "infrastructure_and_utilities_damage                         2327\n",
       "disease_transmission_or_disease_signs_or_symptoms            970\n",
       "missing_trapped_or_found_people                              905\n",
       "treatment                                                    489\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1={'other_useful_information':0, 'missing_trapped_or_found_people':1,\n",
    "       'affectedPeople_or_injured_or_dead_people_or_DeathReports':2,\n",
    "       'donation_needs_or_offers_or_volunteering_services':3,\n",
    "       'sympathy_and_emotional_support':4, 'not_related_or_irrelevant':5,\n",
    "       'prevention_or_caution_and_advice':6,\n",
    "       'infrastructure_and_utilities_damage':7,\n",
    "       'disease_transmission_or_disease_signs_or_symptoms':8, 'treatment':9}\n",
    "def label(x):\n",
    "    return label1[x];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset[\"numeric_label\"]=final_dataset[\"label\"].map(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fear foreigner missing nepal earthquake death toll soar'\n",
      " '700 people dead absolutely devastating country size oklahoma map nepal'\n",
      " 'earthquake nepal please help kapil crowdfunding fundrazr support retweet via mechanismofwar'\n",
      " 'horrible situation nepal god help pita really need simpathy msghelpearth'\n",
      " 'video report kathmandu overwhelmed rubble earthquake 3000 dead 500 plus injured nepalearthquake']\n",
      "corresponding result >>>>>>>>>>>>>>>>>>>>\n",
      "[1 2 3 4 2]\n"
     ]
    }
   ],
   "source": [
    "X = final_dataset['preprocessed'].values# text data will be converted into operational format\n",
    "y=final_dataset['numeric_label'].values #same as it is\n",
    "print(X[0:5])\n",
    "print('corresponding result >>>>>>>>>>>>>>>>>>>>')\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20624, 18497)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vect = TfidfVectorizer()# initializing the vector by creating object\n",
    "X= tf_idf_vect.fit_transform(X) # tranforming text data into vector format\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuuracy>>>> 80.90159961221522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shailesh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_r_model=LogisticRegression(random_state=122, solver='lbfgs' ,multi_class='multinomial').fit(X_train,y_train)\n",
    "y_pred=logistic_r_model.predict(X_test)#after training we pass rest 20%of data for testing purpose\n",
    "acc=metrics.accuracy_score(y_test,y_pred) \n",
    "#here we are passing actual result and predicted result to find out accuracy\n",
    "print('acuuracy>>>>',acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuuracy>>>> 84.53708191953466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_svc_model = LinearSVC(multi_class=\"ovr\") # note perform changes in attribute to get bettter accuracy\n",
    "linear_svc_model.fit(X_train,y_train)#passing data into model for training\n",
    "y_pred=linear_svc_model.predict(X_test)#after training we pass rest 20%of data for testing purpose\n",
    "acc=metrics.accuracy_score(y_test,y_pred) \n",
    "#here we are passing actual result and predicted result to find out accuracy\n",
    "print('acuuracy>>>>',acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 23 23:59:28 2020\n",
      "acuuracy>>>> 72.32186136694135\n",
      "Mon Feb 24 00:06:33 2020\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from time import ctime\n",
    "print(ctime())\n",
    "model = XGBClassifier(objective=\"multi:softmax\",max_depth=4,n_estimator=200)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "acc=metrics.accuracy_score(y_test,y_pred) \n",
    "#here we are passing actual result and predicted result to find out accuracy\n",
    "print('acuuracy>>>>',acc*100)\n",
    "print(ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1, gamma=0,\n",
       "                                            learning_rate=0.1, max_delta_step=0,\n",
       "                                            max_depth=4, min_child_weight=1,\n",
       "                                            missing=None, n_estimators=100,\n",
       "                                            n_jobs=-1, nthread=None,\n",
       "                                            objective='binary:logistic',\n",
       "                                            random_state=0, reg_alpha=0,\n",
       "                                            reg_lambda=1, scale_pos_weight=1,\n",
       "                                            seed=None, silent=None, subsample=1,\n",
       "                                            verbosity=1),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuuracy>>>> 77.55695588948134\n"
     ]
    }
   ],
   "source": [
    "acc=metrics.accuracy_score(y_test,y_pred) \n",
    "#here we are passing actual result and predicted result to find out accuracy\n",
    "print('acuuracy>>>>',acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
